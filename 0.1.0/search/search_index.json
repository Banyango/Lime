{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Lime","text":"<p>Lime wants you have fun programming Agents/LLMs and bring back more control into your hands.</p> <p>Features</p> <ul> <li>Get all the benefits of margarita files now with agentic capabilities.</li> <li>Bring your favourite coding agent (Copilot for now) (roadmap for Claude code, codex and more soon)</li> <li>React like composability through includes <code>[[ my-component is_admin=true ]]</code></li> <li>Store variables in state, and have the LLMs update/fetch state as needed.</li> <li>Don't waste tokens on having LLMs run functions. Run it locally and then pass the results to the LLM.</li> <li>Forget context explosion issues. Surgically control what context is sent to the LLM.</li> <li>Add only the tools you need for a query. Nuke them, then add others and repeat. This keeps context size small and relevant.</li> </ul>"},{"location":"#example","title":"Example","text":"<pre><code>// file:example.mgx\n---\ndescription: Add metadata\nteam: Can put anything in metadata\n---\n\n// Import python functions for use with @effect func\nfrom math import add, subtract, multiply, load_files\n\n// Supports all markdown. Places this into the agent's context.\n&lt;&lt;\nYou are an expert mathematician.\nYour task is to solve addition problems accurately and efficiently.\n\nWhen given a problem, you should:\n1. Read the problem carefully.\n2. Identify the two numbers to be added.\n3. Calculate the sum of the two numbers.\n4. Provide the final answer clearly.\n&gt;&gt;\n\n// Include other margarita files into the context\n[[ create-a-react-component.mg ]]\n\n// Execute a loop \nfor i in items:\n    // run Python functions and store results in state.\n    @effect func add(12, test.data) =&gt; result\n\n// The agent can access/ set state variables too!\n&lt;&lt;\nAdd 12 + test.data and store the result in the variable 'result'.\n&gt;&gt;\n\n// Add tools, note: AddToolParam extends BaseModel from pydantic\n@effect tools add(params: AddToolParams) =&gt; int\n\n// Run the agent using tools and the context you built up.\n@effect run\n\n// clear the context and tools after running to avoid context explosion in future runs.\n@effect context clear\n@effect tools clear\n\n// use the state result variables with a new context.\n&lt;&lt;\nValidate the following:\n- The addition tool correctly adds two numbers.\n- The subtraction tool correctly subtracts two numbers.\n- The multiplication tool correctly multiplies two numbers.\n- The load_files function correctly loads and reads files from the specified directory.\n&gt;&gt;\n\n// conditonal logic\nif result.failed:\n    &lt;&lt;\n    The test failed. Please review the implementation of the math tools and the\n    load_files function for any errors.\n    &gt;&gt;\n    @effect run\nelse:\n    // We're done!\n</code></pre> <p>Hopefully this gives you a taste of the possibilities with Lime!</p>"},{"location":"Coming%20soon/","title":"Plugins (Coming soon)","text":"<p>This feature will allow you to create custom <code>@effect &lt;your_plugin&gt;</code> blocks that can be used to extend the functionality of Lime.</p> <p>This feature is not yet available, but we are working hard to bring it to you soon! Stay tuned for updates.</p>"},{"location":"Conditionals/","title":"Conditionals","text":"<p>Use <code>if</code>/<code>else</code> in templates to branch content.</p> <pre><code>if include_extra:\n    &lt;&lt;Extra section&gt;&gt;\nelse:\n    &lt;&lt;Minimal section&gt;&gt;\n</code></pre>"},{"location":"Context%20Management/","title":"Context Management","text":"<p>Keep the context small and use <code>@effect context clear</code> to reset between runs.</p>"},{"location":"Context%20Management/#example","title":"Example","text":"<p>This example:</p> <ol> <li>Gets 50 books and then summarizes them. </li> <li>Stores the summary in a variable called <code>summary</code> for later use.</li> <li>Clears the context and gets 50 more books </li> <li>Summarizes the new books</li> <li>Then we contrast the new summary with the previous summary stored in the <code>summary</code> variable.</li> </ol> <pre><code>// file:context_management_example.mg\n\n@state summary = \"\"\n\n&lt;&lt;\nYou are a helpful assistant.\n\nI've loaded 50 books into your context so \nyour context is quite large now.\n\nGive a summary of the books.\n\nStore the summary in a variable called \"summary\" for later use.\n&gt;&gt;\n\n@effect run\n\n// If we load another 50 books, the context will be even larger and may cause issues with token limits.\n\n// If we have a second mdx script we would lose any state from the first script.\n\n// Use @effect context clear to reset the context while retaining the `summary` variable.\n@effect context clear\n\n// All variables are retained\n&lt;&lt;\nLoad 50 more books and summarize.\n\nContrast with Previous Summary: ${summary}\n&gt;&gt;\n\n@effect run\n</code></pre>"},{"location":"Custom%20Tools/","title":"Custom Tools","text":"<p>Register tools for the LLM with <code>@effect tools</code> and implement get/set variable helpers.</p> <pre><code>from math import add\n\n&lt;&lt;Add 3 and 5 &gt;&gt;\n\n@effect tools add(x: int, y: int) =&gt; result\n\n@effect run\n</code></pre> <p>This will register the <code>add</code> function as a tool that the LLM can call. </p> <p>Standard prompt engineering techniques can be used to get the LLM to call the tool and pass the correct arguments.</p> <p>Do note that the LLM may not always call the tool, so it's important to design your prompts in a way that encourages the LLM to use the tool when appropriate.</p>"},{"location":"Function%20Calls/","title":"Function Calls","text":"<p>Execute Python functions and save their results to state using <code>@effect func</code>.</p> <p>Note: The Python module (for example, <code>my_module</code>) must be available in the activated Python environment, and the import path must be correct.</p> <pre><code>from my_module import compute\n\n@effect func compute(x) =&gt; result\n</code></pre> <p>The example above calls <code>compute(x)</code> and stores its return value in the <code>result</code> state variable. You can reference this value in subsequent prompts using <code>${result}</code>.</p> <p>Running functions this way avoids consuming LLM tokens for tool calls and lets you invoke deterministic logic directly instead of relying on the model to select the correct tool.</p>"},{"location":"Getting%20started/","title":"Getting started","text":""},{"location":"Getting%20started/#installation","title":"Installation","text":"<p>Run the following command to install Lime:</p> <p>Linux: <pre><code>curl -fsSL https://raw.githubusercontent.com/Banyango/lime/main/install-linux.sh | bash -s -- --option\n</code></pre></p> <p>MacOS: <pre><code>curl -fsSL https://raw.githubusercontent.com/Banyango/lime/main/install-macos.sh | bash -s -- --option\n</code></pre></p> <p>Windows (PowerShell): <pre><code>iwr -useb https://raw.githubusercontent.com/Banyango/lime/main/install-windows.ps1 | iex\n</code></pre></p>"},{"location":"Getting%20started/#copilot","title":"Copilot","text":"<p>Lime is using Copilot (currently), so you will need to have the Copilot CLI installed and configured to use Lime.</p> <p>Note: Lime will be adding support for other agents in the future, but for now Copilot is the only supported agent.</p>"},{"location":"Getting%20started/#your-first-template","title":"Your first template","text":"<p>Create a file named <code>hello.mgx</code> with the following content:</p> <pre><code>---\ndescription: Hello world tutorial for Lime!\n---\n\n&lt;&lt;\n# Hello World\n\nTell the user Hello, and welcome them to Lime!\n&gt;&gt;\n\n@effect run\n</code></pre> <pre><code>lime execute hello.mgx\n</code></pre> <p>Note: This template includes metadata, this is optional but recommended for better organization and discoverability. Metadata can contain any key value pair.</p> <p>The &lt;&lt; &gt;&gt; block contains markdown content, this is the main prompt that you will send to the agent.</p> <p><code>@effect run</code> is a special instruction that tells the agent to execute.</p> <p>Once you run the command, you should see the following output in your terminal:</p>"},{"location":"Getting%20started/#output","title":"Output","text":"<pre><code># Hello World\n\nHello, and welcome to Lime!\n</code></pre> <p>Now that you have run your first template, check out some of the other things you can do with Lime.</p>"},{"location":"Including%20Margarita%20Files/","title":"Including Margarita Files","text":"<p>Lime supports including other Margarita files using the <code>[[ file ]]</code> syntax. This allows you to reuse template fragments across multiple templates.</p>"},{"location":"Including%20Margarita%20Files/#example","title":"Example:","text":"<pre><code>// filename: tester_role.mg\n&lt;&lt;\nYou are a tester AI assistant.\n\nRun playwright tests on the provided files\n\n${files}\n&gt;&gt;\n</code></pre> <pre><code>// filename: page.mgx\n\n[[ tester_role.mg files=[\"test1.spec.ts\", \"test2.spec.ts\"] ]]\n\n@effect run\n</code></pre>"},{"location":"Including%20Margarita%20Files/#see-also","title":"See also","text":"<p>See the Margarita documentation for more details on template syntax, conditionals, loops, and metadata.</p>"},{"location":"Loops/","title":"Loops","text":"<p>Use <code>for</code> loops inside <code>.mgx</code> to generate repeated sections.</p> <pre><code>@state items = [\"apple\", \"banana\", \"cherry\"]\n\nfor i in items:\n    &lt;&lt;Iteration ${i}&gt;&gt;\n</code></pre> <p>The prompt would be loaded with  <pre><code>Iteration apple\nIteration banana\nIteration cherry\n</code></pre></p>"},{"location":"Prompt%20Locking/","title":"Prompt Locking","text":"<p>Prompt integrity locking helps you detect prompt tampering before prompt content is sent to the LLM.</p>"},{"location":"Prompt%20Locking/#why-this-exists","title":"Why this exists","text":"<p>Prompt files can be edited accidentally or maliciously. This feature gives you a deterministic check that says: - \"These are the prompt files we trust.\" - \"These are the exact hashes we expect.\"</p>"},{"location":"Prompt%20Locking/#mental-model","title":"Mental model","text":"<ol> <li><code>prompts.toml</code> is the manifest (what to track).</li> <li><code>prompts.lock.json</code> is the lock (path -&gt; sha256 hash).</li> <li>Preflight verification checks all tracked prompt files against the lock at execute start.</li> <li>Include-time verification checks included prompt bytes before include content is parsed/used.</li> </ol>"},{"location":"Prompt%20Locking/#schema-compatibility","title":"Schema compatibility","text":"<ul> <li><code>prompts.toml</code> and <code>prompts.lock.json</code> carry internal version checks (<code>version = 1</code> in v1) so Lime can fail fast on incompatible schema changes.</li> <li>The lock also pins <code>algorithm = \"sha256\"</code> to keep hashing deterministic and prevent silent verification drift.</li> </ul>"},{"location":"Prompt%20Locking/#one-time-setup","title":"One-time setup","text":"<p>If you are running from source (without globally installing the <code>lime</code> binary), use the Make targets:</p> <pre><code>make prompts-init\nmake prompts-lock\nmake prompts-check\n</code></pre> <p>If you are not using <code>make</code>, run the equivalent source commands directly:</p> <pre><code>uv run python src/main.py prompts init\nuv run python src/main.py prompts lock\nuv run python src/main.py prompts check\n</code></pre> <p>This creates: - <code>prompts.toml</code> - <code>prompts.lock.json</code></p>"},{"location":"Prompt%20Locking/#day-to-day-workflow-for-contributors","title":"Day-to-day workflow (for contributors)","text":"<ol> <li>Edit a tracked prompt file under <code>prompts/</code> (<code>.mg</code> / <code>.md</code>).</li> <li>Run <code>make prompts-check</code> (it should fail until lock is updated).</li> <li>Run <code>make prompts-lock</code> to regenerate hashes.</li> <li>Run <code>make prompts-check</code> again (should pass).</li> <li>Commit both the prompt changes and <code>prompts.lock.json</code>.</li> </ol>"},{"location":"Prompt%20Locking/#runtime-behavior","title":"Runtime behavior","text":"<p>During <code>execute</code>, verification is auto-enabled when <code>prompts.toml</code> exists.</p> <ul> <li>No <code>prompts.toml</code>: execution continues (feature is opt-in).</li> <li><code>prompts.toml</code> exists but lock missing: execution fails (fail-closed).</li> <li>Any tracked file hash mismatch: execution fails.</li> <li>Include outside trusted <code>prompts/</code> root:</li> <li>blocked by default</li> <li>allowed only with <code>--allow-unverified</code></li> <li>Missing include file: execution fails.</li> </ul> <p>When verification is enabled, Lime performs a preflight lock check at execute start and still verifies included prompt bytes before include content is parsed.</p>"},{"location":"Prompt%20Locking/#execute-flag-behavior","title":"Execute flag behavior","text":"<ul> <li><code>--verify-prompts</code>: force verification on (fails if <code>prompts.toml</code> or <code>prompts.lock.json</code> is invalid/missing).</li> <li><code>--no-verify-prompts</code>: force verification off (skip manifest/lock checks for this run).</li> <li><code>--allow-unverified</code>: only affects include paths outside trusted <code>prompts/</code> root; it permits those includes with a warning.</li> </ul> <p>How they interact: - Default (<code>execute</code> with no verify flag): auto mode, verify only when <code>prompts.toml</code> exists. - <code>--allow-unverified</code> only matters when verification is enabled (auto-enabled or <code>--verify-prompts</code>).</p>"},{"location":"Prompt%20Locking/#security-notes","title":"Security notes","text":"<ul> <li>This is tamper-evident integrity and change control, not a complete security boundary.</li> <li>Trust in <code>prompts.lock.json</code> comes from your review process (PR review, protected branches, CI checks).</li> <li>Recommended CI gate: run <code>make prompts-check</code> (or equivalent direct command) on pull requests.</li> </ul>"},{"location":"Running%20the%20Agent/","title":"Running the Agent","text":"<p>Run the agent CLI (example):</p> <pre><code>lime execute example.mgx\n</code></pre>"},{"location":"State/","title":"State","text":"<p>Lime supports storing and accessing state during a run.</p> <pre><code>@state count = 0\n\n&lt;&lt; What is the count variable? &gt;&gt;\n\n@effect run\n</code></pre> <p>The example above defines a state variable named <code>count</code>.</p> <p>To read a value from state, instruct the agent to \"use the <code>count</code> variable\" or \"get count from shared state\"; the system will return the current value. </p> <p>Note that language models can be nondeterministic, so the agent may not always call the state tool.</p> <p>You can also instruct the agent to set or update state values. For example, asking it to \"set count to 5\" or \"update count to 10\" will update the <code>count</code> variable in state (again, the agent may not always call the tool due to model nondeterminism).</p> <pre><code>@state count = 0\n\n&lt;&lt; Set the count variable to 5 &gt;&gt;\n\n@effect run\n</code></pre> <p>The example above sets the <code>count</code> variable to 5.</p>"}]}